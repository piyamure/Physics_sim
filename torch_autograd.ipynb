{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Autograd\n",
    "\n",
    "*  Pytorch automatically computes gradient of operations (or fucntions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1. $R^n \\rightarrow R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* $\\vec{x} = [x_1,x_2,x_3,....,x_n] $ \n",
    " \n",
    "* $f(x) = ||\\vec{x}|| = \\sqrt{x_1^2 + x_2^2 + x_3^2 + ...+x_n^2} $\n",
    "\n",
    "\n",
    "* $\\frac{\\partial \\vec{f}}{\\partial x_j} = 2 x_j $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0592, 0.1185, 0.1777, 0.2369, 0.2962, 0.3554, 0.4146, 0.4739,\n",
       "        0.5331], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(np.arange(10).astype(float),requires_grad=True)\n",
    "y = torch.norm(x)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.05923489 0.11846978 0.17770466 0.23693955 0.29617444\n",
      " 0.35540933 0.41464421 0.4738791  0.53311399]\n"
     ]
    }
   ],
   "source": [
    "# check the differentiation using the exact formula \n",
    "def dy_dx(x):\n",
    "    norm = np.sqrt(np.sum(x**2))\n",
    "    return x/norm\n",
    "\n",
    "x_np = np.arange(10)\n",
    "x_grad = dy_dx(x_np)\n",
    "print(x_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: $R^n \\rightarrow R^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\vec{x} = [x_1,x_2,x_3,....,x_n]$ \n",
    "\n",
    "* $\\vec{f(x)} = [x_1^2 , x_2^2 , x_3^2 , ...,x_n^2] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\frac{\\partial \\vec{f}}{\\partial \\vec{x}} = [\\frac{\\partial \\vec{f}}{\\partial x_1},\\frac{\\partial \\vec{f}}{\\partial x_2},\\frac{\\partial \\vec{f}}{\\partial x_3},.....,\n",
    "\\frac{\\partial \\vec{f}}{\\partial x_n}] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18.], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.detach()\n",
    "x = torch.tensor(np.arange(10).astype(float),requires_grad=True)\n",
    "y2 = x**2\n",
    "y2.backward(torch.ones(10))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  6  8 10 12 14 16 18]\n"
     ]
    }
   ],
   "source": [
    "# check the solution using the exact formula \n",
    "def dy2_dx(x):\n",
    "    return 2*x\n",
    "\n",
    "x_grad = dy2_dx(x_np)\n",
    "print(x_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ \\vec{Q} = 3 \\vec{a}^3 - \\vec{b}^2  $$ \n",
    "\n",
    "$$ \\vec{a} = \\begin{pmatrix} a_1 \\\\ a_2 \\end{pmatrix} $$ \n",
    "\n",
    "$$ \\vec{b} = \\begin{pmatrix} b_1 \\\\ b_2 \\end{pmatrix} $$\n",
    "\n",
    "\n",
    "$$\\vec{Q} = \\begin{pmatrix} Q_1 \\\\ Q_2 \\end{pmatrix} = \\begin{pmatrix} 3 a_1^3 - b_1^2 \\\\ 3 a_2^3 - b_2^2 \\end{pmatrix} $$\n",
    "\n",
    "$$\\vec{J} = \\begin{pmatrix} \\frac{\\partial Q_1}{\\partial a_1} & \\frac{\\partial Q_1}{\\partial b_1} & \\frac{\\partial Q_1}{\\partial a_2} & \\frac{\\partial Q_1}{\\partial b_2} \\\\ \n",
    "\\frac{\\partial Q_2}{\\partial a_1} & \\frac{\\partial Q_2}{\\partial b_1} & \\frac{\\partial Q_2}{\\partial a_2} & \\frac{\\partial Q_2}{\\partial b_2}  \\end{pmatrix}  $$\n",
    "\n",
    "$$\\vec{J} = \\begin{pmatrix} 9 a_1^2 & -2 b_1 & 0 & 0\\\\ \n",
    "0 & 0 & 9 a_2^2 & -2 b_2  \\end{pmatrix}  $$\n",
    "\n",
    "\n",
    "$$\\vec{J}^T \\cdot v^T = \\begin{pmatrix} 9 a_1^2 & 0\\\\ \n",
    "                                        -2 b_1 & -0 \\\\\n",
    "                                        0 & 9 a_2^2 \\\\\n",
    "                                        0 & -2 b_2 \\\\\n",
    "                                         \\end{pmatrix}  \\cdot \\begin{pmatrix} \n",
    "                                         1\\\\ \n",
    "                                         1\n",
    "                                         \\end{pmatrix} = \\begin{pmatrix} 9 a_1^2 \\\\ \n",
    "                                        -2 b_1  \\\\\n",
    "                                        9 a_2^2 \\\\\n",
    "                                       -2 b_2 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(np.arange(4).astype(float),requires_grad=True)\n",
    "b = torch.tensor(np.arange(0,13,4).astype(float),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0., -13., -40., -63.], dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  9., 36., 81.], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.backward(torch.ones(4))\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.,  -8., -16., -24.], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  9., 36., 81.], dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the gradients using the exact values \n",
    "\n",
    "def dQ_da(x):\n",
    "    return 9*x**2\n",
    "\n",
    "def dQ_db(x):\n",
    "    return -2*x\n",
    "\n",
    "dQ_da(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.,  -8., -16., -24.], dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQ_db(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
